# 設計資料集

# コンテナ構造

### 1. フロントエンドコンテナ (User Interface)

ユーザー体験の向上と、非同期処理の可視化を担当します。

- **役割:** Next.jsによるダッシュボードと管理画面の提供。
- **リアルタイム通知:** 画面左下に、処理の状態や完了を即座に知らせる通知機能を搭載します。
- **WebSocketクライアント:** サーバーからの「解析完了」や「エラー」をリアルタイムに受信し、画面をリロードせずに状態を更新します。
- **詳細進捗バー:** `PDF解析中...` → `知見を検索中...` → `AI回答作成中...` といった、Workerから届く細かなフェーズを表示します。

### 2. バックエンドコンテナ (Operating System)

システム全体の司令塔として、リクエストの受付と状態管理を行います。

- **役割:** FastAPIによるAPIの提供、認証、DB管理。
- **Google OAuth認証:** 大学アカウント（@ed.waseda.jp等）によるログイン制限を実装します。
- **ロール自動切替:** DBに登録されたメールアドレスに基づき、管理者・教授・学生の権限を自動付与します。
- **ゾンビタスク監視（Watcher）:** `Processing`状態のまま10分経過したタスクを検知し、自動で`Error`へ変更、または再投入します。
- **WebSocketサーバー:** Workerからの進捗報告を受け取り、フロントエンドへ即座に転送するハブとなります。
- **DBマイグレーション統合:** 起動時に `pgvector` の有効化と、最新のテーブル定義（Alembic/SQL）を自動適用します。

### 3. PDF(TeX)→Text/Markdown パースコンテナ

LLMが理解しやすい形へのデータ加工に特化した専門コンテナです。

- **役割:** アップロードされたPDFやTeXファイルから、構造化されたテキスト（Markdown等）を抽出します。
- **前処理:** 抽象（Abstract）や結論（Conclusion）の特定など、後続のAI解析を助けるメタデータも生成します。ZIPアーカイブの展開機能を追加。`.tex`ファイルが複数ある場合、`is_primary`フラグが立っているファイル（通常は`main.tex`）を起点に再帰的にパースを行う。

### 4. タスク管理コンテナ (Redis)

バックエンドとWorkerを繋ぐ「高機能なTODOリスト」です。

- **役割:** 非同期タスクのキューイング（待ち行列）を管理します。
- **ステータス保持:** 実行中のタスクが現在どのコンテナに投げられているかの情報を一時保持します。

### 5. タスク作業コンテナ (Worker)

Redisからタスクを取り出し、各コンテナを指揮して成果物を完成させる「現場監督」です。

- **役割:** 実際の解析パイプライン（パース → RAG → 推論 → レポート保存）を順次実行します。
- **タイムアウト設定:** 各コンテナ（LLM/パース）へのリクエストに制限時間（例：5分）を設け、フリーズ時にシステムを道連れにしないようにします。
- **リトライ戦略:** 一時的なネットワークエラーに対し、最大3回までの自動再試行を試みます。
- **共有ボリュームアクセス:** ストレージコンテナが作成したキャッシュ領域に直接アクセスし、ファイル転送の遅延をゼロにします。

### 6. LLMコンテナ (Inference Engine)

Ollamaを基盤とした、推論に特化した脳の部分です。

- **役割:** Gemma 3等のモデルを動かし、添削、論理チェック、要約を行います。
- **APIラッパー:** Ollamaの生APIをラップし、リクエストの混雑制御（キューイング）や、エラー時の適切なステータスコード返却を管理します。

### 7. データベースコンテナ (PostgreSQL)

メタデータとベクトルデータの両方を管理する永続化層です。

- **役割:** ユーザーデータ、論文のメタデータ、フィードバック結果の保存。
- **pgvector導入:** ベクトル検索（RAG）を実現し、過去の優秀論文や学会ルールを高速に検索します。

### 8. ストレージコンテナ (Google Drive Operator)

ファイルの永続保存と、高速なキャッシュ管理を両立させるコンテナです。

- **役割:** Google Driveへの自動保存と、バージョン管理の実行。
- **キャッシュ管理:** ダウンロードしたファイルを共有ボリュームへキャッシュし、タイプ別に一定量を超えたら古い順に自動削除します。
- **抽象化API:** 他のコンテナへ「ファイル実体」を送る代わりに、キャッシュ上の「絶対パス（ローカル上の場所）」を返します。
- アップロードされたZIPファイルを検出し、キャッシュボリューム展開時にディレクトリ構造を維持したまま解凍する機能を追加。
- アップロードをタスクで管理し、API制限に引っかからないように抑える。コンテナからのダウンロードは優先的にAPIを使う。それが少ない時間に、アップロードを行う。

---

# ページ設計

1. ログインページ
    - **機能:** Google OAuth認証。
    - **詳細:** 指定ドメイン以外は「アクセス権限がありません」とエラー表示。初回ログイン時は「学生」として自動登録。
    - **追加:** 教授・管理者は事前登録リストと照合し、自動で専用画面へリダイレクト。
2. ダッシュボード（メイン画面）
    - **構成:**
        - **タブ切替:** 「マイ・レポート（添削履歴）」と「ライブラリ（参考論文・集合知）」。
        - **プロジェクトカード:** 論文タイトルごとに集約。現在の最新ステータス（解析中/完了/エラー）をバッジで表示。
        - **バージョン履歴:** カード展開時に、V1, V2...とリスト表示し、それぞれのフィードバックへ飛べるようにします。
    - **通知トレイ（左下常駐）:** WebSocket接続状態、現在実行中のタスク名（キュー待ち数）、詳細な進捗ステップを表示。
3. 論文アップロード・モーダル
    - **モード選択:** 「フィードバックを受ける」or「参考論文として登録（RAG用）」。
    - **ファイル選択:** PDF/TeX/ZIP（複数ファイル用）に対応。ドラッグ＆ドロップ。
    - **著者設定:** 自分以外の著者をユーザー検索から追加（順序入れ替え可能）。
    - **メタデータ:** 学会名（選択式）、年度、タグ（「修士論文」「予稿」など）。
    - **進捗:** 「サーバーへ送信中...」から「解析予約完了」までのアニメーション。
4. フィードバック詳細画面（解析完了後）
    - **プレビューエリア（左）:** PDFビューア。AIが指摘した箇所をハイライト表示（可能であれば）。
    - **情報エリア（右）:**
        - **スコアタブ:** 学会ルールに準拠したレーダーチャート。
        - **指摘タブ:** 修正案をリスト表示。「ソースコード(TeX)を優先参照」した文章の論理チェック結果。
        - **集合知(RAG)タブ:** 過去の類似論文との比較。「〇〇さんのV3の構成と似ていますが、独自性は～」といった記述。
        - **差分(Diff)タブ:** 前回のバージョンからの改善点。
    - **アクション:** 最終レポートのPDF/Markdownエクスポート。
5. 管理画面（教授・特権ユーザー用）
    - **ユーザー管理:** 全ユーザーのリストとロール変更。
    - **学会ルールエディタ:** JSON形式のフォーマット規則をGUIで編集。
    - **システムモニタ:** * **タスクキュー:** Redisに溜まっている未処理件数。
        - **ストレージ状況:** キャッシュボリュームの使用率と、Drive同期ステータス。
        - **計算リソース:** Ollama（LLM）の応答速度。
6. 研究室ライブラリ（検索・集合知ページ）
    
    このページは、研究室に蓄積された膨大な「参考論文」や「過去の先輩の論文」を、AIの力を借りて探索・活用するための**ナレッジセンター**です。
    
    - 役割
        - **知のアーカイブ**: 過去の先輩たちの思考プロセスや、特定の学会（DEIM, IPSJ等）の採択傾向をいつでも参照可能にします。
        - **セマンティック探索**: 「キーワードの一致」だけでなく、RAGを活用した「意味の類似性」による高度な検索を提供します。
    - 主要機能
        - **ハイブリッド検索機能**:
            - **全文/タグ検索**: タイトル、著者、学会、年度、タグによる絞り込み。
            - **AIセマンティック検索**: 「分散システムにおける合意アルゴリズムの先行研究を探して」といった自然言語での検索。
        - **AIナレッジチャット（Ask the Library）**:
            - ライブラリ内の複数の論文を横断的に参照し、「この研究室では過去にどのような評価実験が主流だったか？」といった問いに、出典（論文名とページ）を明記して回答します。
        - **論文ギャラリー（タイル表示）**:
            - 論文のAbstract（概要）をAIが要約してカード形式で表示。中身を開かなくても内容が把握できます。
        - **トレンド・ヒートマップ**:
            - 研究室でどの学会への提出が多いか、どのキーワードが流行っているかを可視化します。

---

# フロー設計

## 論文解析フロー (非同期パイプライン)

1. **Frontend**: ファイルとメタデータをPOST。
2. **Backend**: ファイルをCacheに保存、DBに `Task(Pending)` 作成。**ファイルハッシュを確認し、重複なら処理スキップ。** Redisへタスク投入。
3. **Worker**: タスクを取得しDBを `Processing` に更新。
4. **Worker (並列処理)**:
    - **同期依頼**: StorageへDriveアップロード指示。
    - 前回との比較
        - **テキスト取得**: 今回のパース結果を取得。
        - **過去データ検索**: DBから同じ `paper_id` で、一つ前の `version_number` のテキスト（またはパース済みMarkdown）を取得。
        - **物理差分生成**: `difflib` 等のライブラリを用いて、Markdownレベルでの差分を作成。
        - **意味差分生成 (LLM)**:
            - LLMに「前回のフィードバック内容」と「今回の変更点」の両方を渡し、**「前回の指摘が修正されているか？」**を判定させる。
        - **保存**: 結果を `version_diffs` に格納。
    - **パース:** ParserコンテナにCache上のパスを伝え、Markdown化。**同時にPDFの場合は各テキスト片の座標データを抽出してDB(embeddings)に保存する。**」
5. **Worker (RAG & LLM)**: 類似論文検索（RAG）とLLM推論（5分タイムアウト/3回リトライ）。
6. **Worker (完了確認)**: **Storageから「Drive保存完了」のシグナルを確認。**
7. **Worker (報告)**: DB更新、Redisへ完了通知をパブリッシュ。
8. **Backend**: WebSocket経由で通知。**フロント側は通知受信時に「最新のFBリスト」を自動再取得。**

## キャッシュ管理フロー

1. **Storage**: 1時間ごとにディスク監視。
2. **Storage**: **DBを参照し、`Pending` `Processing` および「直近一週間に使用したファイル」を除外。**
3. **Storage**: 古い順に物理削除、`is_cached = False` に更新。
4. **Storage:** ストレージで5GBを超えると、最終使用の古いものから削除。`is_cached = False` に更新。

## **想定操作とそれに対するフロー**

- ユーザーログイン
    - googleアカウントでログイン
    - ダッシュボードへリダイレクト
        - 教授や管理者ならそれ用のページへリダイレクト
- 論文アップロード (共通)
    - **ハッシュチェック:** アップロード時に過去の自分のファイルと同一かチェックし、同じなら「解析済みです」と表示して無駄なリソース消費を防ぎます。
    - **キュー待ち表示:** Redis内の未処理タスク数に基づき、通知欄に「解析待ち：あと〇人」と出すとユーザーが安心します。
- 論文アップロード (FB利用)
    
    ユーザーが「いま何が起きているか」を把握できるフローにします。
    
    1. **アップロード**: PDF（必須）と、あればMD/TXTを選択。学会メタデータを選択。
    2. **受付**: 「サーバーが受け取りました」のメッセージと共にダッシュボードへ戻る。
    3. **表示**: ダッシュボード左下の通知欄に「[論文名] 解析中... (1/3: 構造解析中)」のような詳細進捗を表示。
        - ※WorkerがDBの `inference_tasks.status` を更新するたびにBackendがWebSocketで流します。
    4. **完了**: 通知トレイが緑色に光り、「解析が完了しました」と表示。
- 論文アップロード (参考論文)
    
    参考論文は「フィードバック」は不要ですが、「RAGの検索対象（集合知）」として登録するフローが必要です。
    
    1. **アップロード**: 複数ファイルを選択。メタデータ（学会名、年度、ゼミ/一般など）を設定。
    2. **自動パース**: BackendはRedisに **「タグ：REFERENCE_ONLY」** のタスクを投入。
    3. **Worker**: タグを見て「LLMによる解析」をスキップし、**「Parserによるテキスト化」と「pgvectorへのEmbedding保存」のみ**を実行。
    4. **完了**: これにより、次回以降のFB利用アップロード時に、この論文が「知見」として検索されるようになります。
- フィードバック閲覧
    - ダッシュボードから、フィードバックボタンをクリック
    - 最新順に並んだ自分の論文(バージョンごと)のFB一覧を表示
    - 任意の論文をクリック
    - **キャッシュ復元フロー:** もし古い論文のFBを見ようとして `is_cached = False` だった場合、ストレージコンテナがバックグラウンドでDriveから再ロードし、表示させる「オンデマンド・キャッシュ復元」を組み込みます。
    - そのバージョンのフィードバックを表示

---

# データベース設計

### 1. users (ユーザー管理)

大学のGoogle認証（OAuth2）を起点とするユーザーテーブル。

- **id**: `UUID` または `SERIAL` (主キー)
- **email**: `VARCHAR` (一意制約、ドメイン制限に使用)
- **name**: `VARCHAR` (表示名)
- **role**: `ENUM` ('Admin', 'Professor', 'Student')
- **last_login_at**: `TIMESTAMP` (最終ログイン日時)

### 2. papers (論文基本情報)

論文の箱となるメタデータ。

- **paper_id**: `SERIAL` (主キー)
- **owner_id**: `INTEGER` (管理責任者・アップロード者のID)
- **title**: `VARCHAR` (論文のタイトル)
- **status**: `VARCHAR` ('Completed', 'Processing', 'Error') - 論文全体の最新状態
- **is_deleted**: `BOOLEAN` (論理削除フラグ。Trueの場合は一覧に表示しない)

### 3. paper_authors (著者管理 - 中間テーブル)

1つの論文に連なる複数の著者を管理。

- **paper_id**: `INTEGER` (外部キー)
- **user_id**: `INTEGER` (外部キー)
- **author_order**: `INTEGER` (1: 第一著者, 2: 第二著者...)
- **is_corresponding_author**: `BOOLEAN` (責任著者フラグ)
- **PRIMARY KEY (paper_id, user_id)**

### 4. versions (論文バージョン管理)

「第n回提出」という時間軸の管理。

- **version_id**: `SERIAL` (主キー)
- **paper_id**: `INTEGER` (外部キー)
- **version_number**: `INTEGER` (提出回数)
- **created_at**: `TIMESTAMP` (提出日時)

### 5. files (ファイル実体管理)

1つのバージョンに含まれるPDF、TeX、画像などの実体管理。

- **file_id**: `SERIAL` (主キー)
- **version_id**: `INTEGER` (外部キー)
- **file_role**: `ENUM` ('main_pdf', 'source_tex', 'additional_file')
- **is_primary**: `BOOLEAN` (Workerがパース対象とする主ファイルか)
- **drive_file_id**: `VARCHAR` (Google DriveのファイルID)
- **cache_path**: `VARCHAR` (キャッシュボリューム内のパス)
- **is_cached**: `BOOLEAN` (現在キャッシュ上に存在するか)
- **file_hash**: `VARCHAR` (MD5/SHA256など)
- **original_filename:** `VARCHAR` (ZIP展開時などの元々のファイル名を保持)

### 6. feedbacks (解析結果報告)

AI Workerが出力した最終成果。

- **feedback_id**: `SERIAL` (主キー)
- **version_id**: `INTEGER` (外部キー)
- **task_id**: `INTEGER` (生成元となったタスクID)
- **score_json**: `JSONB` (カテゴリ別の点数)
- **comments_json**: `JSONB` (具体的な指摘事項)
- **overall_summary**: `TEXT` (AIによる総評)
- **created_at**: `TIMESTAMP`

### 7. inference_tasks (タスク監視・リトライ管理)

非同期処理の実行状態。フロントエンドの進捗表示のソース。

- **task_id**: `SERIAL` (主キー)
- **version_id**: `INTEGER` (外部キー)
- **status**: `VARCHAR` ('Pending', 'Parsing', 'RAG', 'LLM', 'Completed', 'Error')
- **error_message**: `TEXT` (失敗時の詳細)
- **retry_count**: `INTEGER` (現在の試行回数。最大3回)
- **conference_rule_id**: `VARCHAR` (適用した学会ルール)
- **started_at**: `TIMESTAMP` (開始時刻)
- **completed_at**: `TIMESTAMP` (終了時刻)

### 8. embeddings (RAG・ベクトル検索用)

`pgvector` を使用した検索用データ。

- **id**: `SERIAL` (主キー)
- **file_id**: `INTEGER` (どのファイルから抽出されたか)
- **chunk_index**: `INTEGER` (ファイル内での出現順序)
- **section_title**: `VARCHAR` (抽出元の章タイトル)
- **page_number / line_number**: `INTEGER` (出典特定用)
- **content_chunk**: `TEXT` (分割された文章)
- **location_json :** `JSONB` (PDF内の座標情報（`{"page": 1, "bbox": [x0, y0, x1, y1]}`）を格納。これにより、フロントエンドでのハイライト表示を可能にする。)
- **embedding**: `VECTOR(1536)` (OpenAIやGemmaの埋め込み次元数に合わせる)

### 9. conference_rules (学会別ルール定義)

- **rule_id**: `VARCHAR` (主キー: 'DEIM', 'IPSJ' 等)
- **name**: `VARCHAR` (学会名)
- **format_rules**: `JSONB` (制約事項)
- **style_guide**: `TEXT` (推奨表現など)

### 10. **version_diffs (バージョン間差分管理)**

- `diff_id`: SERIAL (主キー)
- `current_version_id`: INTEGER (今回のバージョン)
- `previous_version_id`: INTEGER (比較対象の旧バージョン)
- `text_diff_json`: JSONB (行単位、単語単位の物理的な差分データ)
- `semantic_diff_text`: TEXT (AIによる「何が改善されたか」の要約)
- `created_at`: TIMESTAMP

---

# ストレージ設計

- **永続層 (Google Drive)**:
    
    ```
    /nak-base
    ├── projects/                      (添削用：マイプロジェクト)
    │     └── {paper_id}/              (論文ごとのフォルダ)
    │           └── v{n}/              (バージョンごとのフォルダ)
    │                 ├── main.pdf     (file_role: main_pdf)
    │                 ├── source.tex   (file_role: source_tex)
    │                 └── images.zip   (file_role: additional_file)
    └── library/                       (検索用：研究室ライブラリ)
    └── {category_id}/           (学会名や年度：DEIM2025 等)
    ├── {file_id}.pdf
    └── {file_id}.tex
    ```
    
- **キャッシュ層 (Shared Docker Volume)**:
    
    WorkerやParserが高速にアクセスするための「作業場」です。
    
    - **マウントパス**: `/cache`
    - **構造**: `/cache/{file_id}.{ext}`
    - ファイル書き込み中は `{file_id}.tmp` として保存し、完了した瞬間に `rename` して `.pdf` 等にする「アトミック書き込み」を徹底します。
    - **設計意図**:
        - ディレクトリを深くせず、フラットに配置することで、DBの `file_id` と一対一で即座に紐付けます。
        - 拡張子（`.pdf`, `.tex`）を付与することで、Parser等の外部ツールがファイル形式を判別しやすくします。
- **抽象化API**:
    - `GET /storage/path/{file_id}` に対し、キャッシュがあれば `/cache/...` の絶対パスを返し、なければDriveから取得してキャッシュした上でパスを返します。
- 

---

# エンティティ設計 (Entity Design)

アプリケーション層（FastAPI）で扱う主要なデータモデル（Pydantic/SQLAlchemy）の定義です。

### Core Entities

- **User**: `id`, `email`, `name`, `role`（認可ロジックの基盤）
- **Paper**: `id`, `title`, `owner_id`, `status`（論文プロジェクトのメタデータ）
- **Version**: `id`, `paper_id`, `version_number`, `files[]`（提出単位）
- **File**: `id`, `version_id`, `file_role`, `is_primary`, `cache_path`, `is_cached`（ファイル実体管理）
- **InferenceTask**: `id`, `version_id`, `status`, `retry_count`, `error_message`（非同期状態の管理）
- **Feedback**: `id`, `task_id`, `score_json`, `comments_json`, `summary`（AIの成果物）

### Search/RAG Entities

- **EmbeddingChunk**: `id`, `file_id`, `text`, `vector`, `location_json`（ベクトル検索の最小単位）
- **ConferenceRule**: `id`, `name`, `format_rules`（学会別バリデーション基準）

---

# エンドポイント設計 (Endpoint Design)

フロントエンドとバックエンドが会話するためのAPI定義です。

### 認証・ユーザー系

- `POST /auth/login`: Google OAuth2連携。セッション/JWT発行。
- `GET /users/me`: ログインユーザーのプロフィールとロール取得。

### 論文操作系

- `GET /papers`: 自分が著者またはオーナーである論文一覧。
- `POST /papers/upload`: 新規論文/新バージョンのアップロード（Multipart/form-data）。
- `GET /papers/{paper_id}/versions`: 特定論文の履歴一覧。
- `GET /feedbacks/{version_id}`: フィードバック結果の取得。

### 研究室ライブラリ（集合知）系

- `GET /library/search`: セマンティック検索（RAG）。
- `POST /library/chat`: 過去論文に基づいたAIチャット相談。
- `POST /library/upload`: 参考論文の登録（REFERENCE_ONLYタスク）。

### システム・リアルタイム系

- `WS /ws/notifications`: WebSocketによる進捗プッシュ通知。
- `GET /tasks/{task_id}`: 特定タスクの現在のステータス詳細。

---

# ツール設計 (Tool & Service Design)

各コンテナの責務を果たすためのモジュール・サービス群です。

- **StorageService**:
    - Google Driveへのアップロード・ダウンロード。
    - キャッシュボリュームの管理、アトミックなファイル書き込み（`.tmp`→`.pdf`）。
- **ParserService**:
    - PDF/TeXのパース、座標データの抽出。
    - ZIPファイルの解凍とディレクトリ構造の走査。
- **LLMAgentService**:
    - Ollama APIとの通信（APIラッパー経由）。
    - RAG（pgvector検索結果）をプロンプトに注入するコンテキスト管理。
- **TaskDispatcher**:
    - Redisキューへのタスク投入。
    - Workerプロセスのライフサイクル管理。
- **DiffEngine (Worker内モジュール)**:
    - 2つのテキストを入力とし、フロントエンド（`react-diff-view`等）が解釈できる形式（Unified Diff形式など）を出力する機能。

---

# 関数設計 (Function Logic Design)

システムの核心となる主要なロジックの流れです。

### `process_paper_analysis_task(task_id)`

Worker内で実行されるメインロジック。

1. **Init**: DBからタスクとファイルパスを取得。ステータスを `Parsing` へ。
2. **Parse**: `ParserService` でテキストと座標を抽出。PDFならハイライト用座標を保持。
3. **Embed**: 抽出テキストをチャンク分割し、`pgvector` に保存。
4. **RAG**: 学会ルールとライブラリ内の類似論文を検索し、コンテキストを作成。
5. **Inference**: `LLMAgentService` を呼び出し（5分タイムアウト監視）。
6. **Report**: `Feedbacks` テーブルに結果を保存し、ステータスを `Completed` へ。
7. **Notify**: Redis Pub/Sub 経由で完了シグナルを送信。

### `get_valid_cache_path(file_id)`

ストレージコンテナの「オンデマンド・キャッシュ復元」ロジック。

1. ローカルの `/cache/{file_id}` を確認。
2. 存在すればそのパスを返す。
3. 存在しなければ、DBから `drive_file_id` を引き、Google Driveからダウンロード。
4. ダウンロード完了後、`is_cached = True` に更新してパスを返す。

---